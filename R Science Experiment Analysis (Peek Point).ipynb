{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import inspect, os, sys, copy, pytz, re, glob\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pybloom\n",
    "from collections import Counter, defaultdict\n",
    "utc=pytz.UTC\n",
    "\n",
    "ENV = \"production\"\n",
    "os.environ['CS_ENV'] = 'production'\n",
    "BASE_DIR = \"/home/reddit/CivilServant\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"config\") + \"/{env}.json\".format(env=ENV), \"r\") as config:\n",
    "  DBCONFIG = json.loads(config.read())\n",
    "\n",
    "### LOAD SQLALCHEMY\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text\n",
    "\n",
    "db_engine = create_engine(\"mysql://{user}:{password}@{host}/{database}\".format(\n",
    "    host = DBCONFIG['host'],\n",
    "    user = DBCONFIG['user'],\n",
    "    password = DBCONFIG['password'],\n",
    "    database = DBCONFIG['database']))\n",
    "DBSession = sessionmaker(bind=db_engine)\n",
    "\n",
    "### LOAD PRAW\n",
    "import reddit.connection\n",
    "conn = reddit.connection.Connect(base_dir=BASE_DIR, env=\"jupyter\")\n",
    "\n",
    "### FILTER OUT DEPRECATION WARNINGS ASSOCIATED WITH DECORATORS\n",
    "# https://github.com/ipython/ipython/issues/9242\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of this Notebook\n",
    "The goal of this notebook is to analyze the r/science experiment partway through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PRAW session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = conn.connect(controller=\"ModLog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset of Posts Appearing In the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_posts = []\n",
    "for row in db_engine.execute(text(\"select * from experiment_things JOIN posts on experiment_things.id = posts.id WHERE object_type=1 AND experiment_id=6 ORDER BY posts.created ASC;\")):\n",
    "    post = {}\n",
    "    for key in row.keys():\n",
    "        post[key]=row[key]\n",
    "    metadata = json.loads(row['metadata_json'])\n",
    "    for key in metadata['condition'].keys():\n",
    "        post[key] = metadata['condition'][key]\n",
    "    post['treat.number'] = int(post[''])\n",
    "    del post['']\n",
    "    del post['metadata_json']\n",
    "    if post['block.id'].find(\"nonama\") != -1:\n",
    "        post['AMA'] = False\n",
    "    else:\n",
    "        post['AMA'] = True\n",
    "    post['post_data']  = json.loads(post['post_data'])\n",
    "    experiment_posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{0} posts have been assigned to treatment or control in the experiment.\".format(len(experiment_posts)))\n",
    "earliest_date = experiment_posts[0]['created']\n",
    "latest_date = experiment_posts[-1]['created']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import app.time_on_page_script as tops\n",
    "# import utils.common\n",
    "\n",
    "# counter = 0\n",
    "# for post in experiment_posts:\n",
    "#     counter+=1\n",
    "#     if counter % 5 ==0:\n",
    "#         sys.stdout.write(\".\")\n",
    "#         sys.stdout.flush()\n",
    "#     time_on_top = tops.time_on_page(\n",
    "#             post['id'], \"mouw\", utils.common.PageType.TOP, rank_limit=5, start_time=earliest_date,\n",
    "#             end_time = datetime.datetime.now()\n",
    "#         )\n",
    "#     post['sub.top.minute']  = time_on_top['total_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tops.time_on_page(\n",
    "#             experiment_posts[0]['id'], \"mouw\", utils.common.PageType.TOP, rank_limit=5, start_time=earliest_date,\n",
    "#             end_time = datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Moderator Actions Going Back to the Earliest Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent_mod_actions = []\n",
    "for row in db_engine.execute(text('select action_data from mod_actions WHERE subreddit_id=\"mouw\" AND created_utc >= \"{0}\" ORDER BY created_utc;'.format(earliest_date))):\n",
    "    mod_action = json.loads(row['action_data'])\n",
    "    mod_action['created'] = utc.localize(datetime.datetime.utcfromtimestamp(mod_action['created_utc']))\n",
    "    recent_mod_actions.append(mod_action)\n",
    "print(\"{0} moderator actions loaded\".format(len(recent_mod_actions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag posts as visible or non-visible based on moderation log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_2016 = {}\n",
    "for post in experiment_posts:\n",
    "    post['visible'] = True\n",
    "    posts_2016[post['id']] = post\n",
    "recent_post_count = len(posts_2016.values())\n",
    "print(\"Post Count: {0}\".format(recent_post_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing posts mentioned in the moderation log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_mod_actions = []\n",
    "matched_mod_actions = 0\n",
    "for action in recent_mod_actions:\n",
    "    if action['action'] == \"removelink\":\n",
    "        key = action['target_fullname'].replace(\"t3_\",\"\")\n",
    "        if key in posts_2016.keys():\n",
    "            posts_2016[key]['visible'] = False\n",
    "            matched_mod_actions += 1\n",
    "        else:\n",
    "            missing_mod_actions.append(key)\n",
    "    elif action['action'] == 'approvelink':\n",
    "        key = action['target_fullname'].replace(\"t3_\",\"\")\n",
    "        if key in posts_2016.keys():\n",
    "            posts_2016[key]['visible'] = True\n",
    "            matched_mod_actions += 1\n",
    "        else:\n",
    "            missing_mod_actions.append(key)\n",
    "#print(\"Missing Mod Actions: {0}\".format(len(missing_mod_actions)))\n",
    "print(\"Missing Mod Action Posts: {0}\".format(len(set(missing_mod_actions))))\n",
    "print(\"Matched Mod Actions: {0}\".format(matched_mod_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch missing posts from reddit to examine\n",
    "#### Looks like the missing posts were ones that were removed immediately by automoderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extra_posts = []\n",
    "#for submission in r.get_submissions([\"t3_\" + x for x in set(missing_mod_actions)]):\n",
    "#    extra_posts.append(submission.json_dict)\n",
    "#print(len(extra_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create Dataframe to Chart Submitted versus Permitted Posts Per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent_posts = pd.DataFrame(list(posts_2016.values()))\n",
    "print(\"Posts before update from modlog: {0}\".format(recent_post_count))\n",
    "print(\"Posts after update from modlog: {0}\".format(recent_posts.created.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Posts Per Day in Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TOTAL SUBMISSIONS\n",
    "df = recent_posts[((recent_posts.created <= latest_date) &\n",
    "                   (recent_posts.created >= earliest_date))]\n",
    "x = pd.DataFrame(df.created.values, index=df.created.values.astype('datetime64'))\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "x.resample(\"D\").count().plot(rot=45, ax=ax)\n",
    "plt.ylim([0,x.resample(\"D\").count()[0].max() + 10])\n",
    "plt.title(\"Total number of submissions per day accepted by AutoModerator, r/science, in reddit + baumgartner data (n={0})\".format(df.created.count()), fontsize=\"24\")\n",
    "plt.show()\n",
    "\n",
    "total_counts = x.resample(\"D\").count().to_dict(\"records\")\n",
    "\n",
    "### NOW ACCEPTED SUBMISSIONS\n",
    "df = recent_posts[((recent_posts.visible == True) & \n",
    "                   (recent_posts.created <= latest_date) &\n",
    "                   (recent_posts.created >= earliest_date))]\n",
    "x = pd.DataFrame(df.created.values, index=df.created.values.astype('datetime64'))\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "x.resample(\"D\").count().plot(rot=45, ax=ax)\n",
    "plt.ylim([0,x.resample(\"D\").count()[0].max() + 10])\n",
    "plt.title(\"Total number of visible submissions per day, r/science, in reddit + baumgartner data (n={0})\".format(df.created.count()), fontsize=\"24\")\n",
    "plt.show()\n",
    "\n",
    "retained_counts = x.resample(\"D\").count().to_dict(\"records\")\n",
    "\n",
    "### NOW REMOVED SUBMISSIONS\n",
    "df = recent_posts[((recent_posts.visible == False) & \n",
    "                   (recent_posts.created <= latest_date) &\n",
    "                   (recent_posts.created >= earliest_date))]\n",
    "x = pd.DataFrame(df.created.values, index=df.created.values.astype('datetime64'))\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "x.resample(\"D\").count().plot(rot=45, ax=ax)\n",
    "plt.ylim([0,x.resample(\"D\").count()[0].max() + 10])\n",
    "plt.title(\"Total number of moderator-removed submissions per day (), r/science, in reddit + baumgartner data (n={0})\".format(df.created.count()), fontsize=\"24\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Dependent Variables: \n",
    "* newcomer comments on posts that are allowed to remain\n",
    "* the number of newcomer comments on posts that are allowed to remain\n",
    "* the number of removed newcomer comments on posts that are allowed to remain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load last six months of comments from official reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment_head = parser.parse(\"2015-12-01 00:00:00 UTC\")\n",
    "all_comments = {}\n",
    "comment_ids = pybloom.BloomFilter(capacity=10000000, error_rate = .000000001)\n",
    "\n",
    "for filename in [#'/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_12_2015.json',\n",
    "#                 '/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_01_2016.json',\n",
    "#                 '/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_02_2016.json',\n",
    "                 '/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_03_2016.json',\n",
    "                 '/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_04_2016.json',\n",
    "                 '/mnt/corsair/reddit_archive/official-bigquery-data/science_comments_05_2016.json']:\n",
    "    sys.stdout.write(\".\")\n",
    "    sys.stdout.flush()\n",
    "    with open(filename, \"r\") as lines:\n",
    "        for line in lines:\n",
    "            comment = json.loads(line)\n",
    "            if(comment['id'] not in comment_ids):\n",
    "                comment['created'] = utc.localize(datetime.datetime.utcfromtimestamp(float(comment['created_utc'])))\n",
    "                comment['visible'] = True\n",
    "                if(comment['body'] == \"[removed]\"):\n",
    "                    comment['visible'] = False\n",
    "                comment['body.length'] = len(comment['body'])\n",
    "                comment['body'] = None\n",
    "                comment['body_html'] = None\n",
    "                all_comments[comment['id']] = comment\n",
    "                comment_ids.add(comment['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Baumgartner Comments from June 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Omitting tails for this analysis\n",
    "#tail = parser.parse('2016-05-30 23:59:59 UTC')\n",
    "count = 0\n",
    "with open(\"/mnt/corsair/reddit_archive/baumgartner-bigquery-data/baumgartner_science_comments_2016_08_01_1900.json\", \"r\") as comment_file:\n",
    "    for line in comment_file:\n",
    "        comment = json.loads(line)\n",
    "        if(comment['id'] not in comment_ids):\n",
    "            comment['created'] = parser.parse(comment['created_utc'])\n",
    "#            if(comment['created'] <= tail):\n",
    "            comment['body.length'] = len(comment['body'])\n",
    "            comment['body'] = None\n",
    "            comment['body_html'] = None\n",
    "            comment['visible'] = True\n",
    "            if(comment['body'] == \"[removed]\"):\n",
    "                comment['visible'] = False\n",
    "            all_comments[comment['id']] = comment\n",
    "            comment_ids.add(comment['id'])\n",
    "        count += 1\n",
    "        if(count % 50000 == 0):\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "with open(\"/mnt/corsair/reddit_archive/baumgartner-bigquery-data/baumgartner_science_comments_2016_09_16_1500.json\", \"r\") as comment_file:\n",
    "    for line in comment_file:\n",
    "        comment = json.loads(line)\n",
    "        if(comment['id'] not in comment_ids):\n",
    "            comment['created'] = parser.parse(comment['created_utc'])\n",
    "#            if(comment['created'] <= tail):\n",
    "            comment['body.length'] = len(comment['body'])\n",
    "            comment['body'] = None\n",
    "            comment['body_html'] = None\n",
    "            comment['visible'] = True\n",
    "            if(comment['body'] == \"[removed]\"):\n",
    "                comment['visible'] = False\n",
    "            all_comments[comment['id']] = comment\n",
    "            comment_ids.add(comment['id'])\n",
    "        count += 1\n",
    "        if(count % 50000 == 0):\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Comments from CivilServant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbcomments = []\n",
    "count = 0\n",
    "for row in db_engine.execute(text(\"select * from comments WHERE subreddit_id='mouw';\")):\n",
    "    comment = {}\n",
    "    for key in row.keys():\n",
    "        comment[key] = row[key]\n",
    "    comment_data = json.loads(comment['comment_data'])\n",
    "    for key in comment_data.keys():\n",
    "        comment[key] = comment_data[key]\n",
    "    del comment['comment_data']\n",
    "#    if(comment['link_id'].replace(\"t3_\", \"\") in posts_2016.keys()):\n",
    "    dbcomments.append(comment)\n",
    "    \n",
    "    if(comment['id'] not in all_comments.keys()):\n",
    "        comment['created'] = utc.localize(datetime.datetime.utcfromtimestamp(comment['created_utc']))\n",
    "#       if(comment['created'] <= tail):\n",
    "        comment['body.length'] = len(comment['body'])\n",
    "        comment['body'] = None\n",
    "        comment['body_html'] = None\n",
    "        comment['visible'] = True\n",
    "        if(comment['body'] == \"[removed]\"):\n",
    "            comment['visible'] = False\n",
    "            \n",
    "    count += 1\n",
    "    if(count % 5000 == 0):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parser.parse(comment['created_utc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Missing Coments from Moderation Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "missing_comment_ids = []\n",
    "for action in recent_mod_actions:\n",
    "    if action['target_fullname'] is not None and \"t1_\" in action['target_fullname']:\n",
    "        link_id = re.search('/r/science/comments/(.*?)/', action['target_permalink']).group(1)\n",
    "        if action['target_fullname'].replace(\"t1_\", \"\") not in all_comments.keys():\n",
    "            missing_comment_ids.append(action['target_fullname'])\n",
    "print(\"Missing Comments: {0}\".format(len(missing_comment_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### FETCH COMMENT INFORMATION FOR ALL MISSING COMMENTS\n",
    "missing_comments = []\n",
    "counter = 0\n",
    "for comment_obj in r.get_info(thing_id=missing_comment_ids):\n",
    "    comment = comment_obj.json_dict\n",
    "    comment['created'] = utc.localize(datetime.datetime.utcfromtimestamp(float(comment['created_utc'])))\n",
    "    comment['visible'] = True\n",
    "    if(comment['body'] == \"[removed]\" or comment['banned_by'] is not None):\n",
    "        comment['visible'] = False\n",
    "    comment['body.length'] = len(comment['body'])\n",
    "    comment['body'] = None\n",
    "    comment['body_html'] = None\n",
    "    missing_comments.append(comment)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Found {0} additional comments moderated during the newcomer period and moderation log period\".format(len(missing_comments)))\n",
    "print(\"{0} of these comments have the author [deleted]\".format(len([x for x in missing_comments if x['author']==\"[deleted]\"])))\n",
    "print(\"{0} of these comments were removed.\".format(len([x for x in missing_comments if x['visible']==False])))\n",
    "mod_action_head = recent_mod_actions[0]['created']\n",
    "comments_in_comment_period = len([x for x in missing_comments if (mod_action_head < x['created'])])\n",
    "print(\"{0} of these fall within the period covered by the moderation log.\".format(comments_in_comment_period))\n",
    "\n",
    "newcomer_head = parser.parse(\"2016-01-01 00:00:00 UTC\")\n",
    "comments_in_newcomer_period = len([x for x in missing_comments if (newcomer_head < x['created'])])\n",
    "print(\"{0} of these fall within the period used for calculating newcomers.\".format(comments_in_newcomer_period))\n",
    "\n",
    "added_count = 0\n",
    "for comment in missing_comments:\n",
    "    if(comment['created'] >= newcomer_head): #and comment['created'] <= tail):\n",
    "        all_comments[comment['id']] = comment\n",
    "        added_count +=1\n",
    "print(\"\")\n",
    "print(\"{0} comments added to all_comments\".format(added_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a time sorted list of comments on the sampled posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "EPOCH = utc.localize(datetime.datetime.utcfromtimestamp(0))\n",
    "\n",
    "class CommentHeapObj(object):\n",
    "    def __init__(self, comment):\n",
    "        self.index = int((comment['created'] - EPOCH).total_seconds())\n",
    "        self.val = comment\n",
    "    def __lt__(self, other):\n",
    "        return self.index < other.index\n",
    "\n",
    "def heapsort(comments):\n",
    "    h = []\n",
    "    for comment in comments:\n",
    "        heapq.heappush(h, CommentHeapObj(comment))\n",
    "    return [heapq.heappop(h).val for i in range(len(h))]\n",
    "\n",
    "all_comments = heapsort(all_comments.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Moderation Actions to Comments, Setting Comments as Visible or Not Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "mod_comment_actions = defaultdict(list)\n",
    "approved_count = 0\n",
    "removed_count = 0\n",
    "total_coments_removed_at_least_once = []\n",
    "comments_with_mod_actions = set()\n",
    "\n",
    "for action in recent_mod_actions:\n",
    "     if action['action'] == \"removecomment\" or action['action'] == \"approvecomment\":\n",
    "            comment_id = action['target_fullname'].replace(\"t1_\", \"\")\n",
    "            mod_comment_actions[comment_id].append(action)\n",
    "            comments_with_mod_actions.add(action['target_fullname'])\n",
    "\n",
    "print(\"{0} Total moderation actions\".format(sum([len(x) for x in mod_comment_actions.values()])))\n",
    "print(\"{0} Comments with moderation actions\".format(len(mod_comment_actions)))\n",
    "print(\"{0} Comments with more than one mod action\".format(len([x for x in mod_comment_actions.values() if len(x)>1])))\n",
    "print(\"\")\n",
    "\n",
    "for comment in all_comments:\n",
    "    if('later_deleted' not in comment.keys()):\n",
    "        comment['later_deleted'] = False\n",
    "        if(comment['author'] ==\"[deleted]\"):\n",
    "            comment['later_deleted'] = True\n",
    "    if comment['id'] in mod_comment_actions.keys():\n",
    "        for action in mod_comment_actions[comment['id']]:\n",
    "            ## many authors are later deleted, so try to \n",
    "            ## add in the author information here, since\n",
    "            ## the moderation log retains the author information\n",
    "            comment['author']  = action['target_author']\n",
    "            if action['action'] ==\"removecomment\":\n",
    "                removed_count += 1\n",
    "                total_coments_removed_at_least_once.append(comment['id'])\n",
    "                comment['visible'] = False\n",
    "            elif action['action'] == \"approvecomment\":\n",
    "                approved_count += 1\n",
    "                comment['visible']  = True\n",
    "print(\"Summary of Comment Visibility:\")\n",
    "print(Counter([x['visible'] for x in all_comments]))\n",
    "print(\"Took {0} actions to set a comment to removed\".format(removed_count))\n",
    "print(\"Took {0} actions to set a comment to approved\".format(approved_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Author Comment Number to All Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_comment_num = defaultdict(int)\n",
    "\n",
    "for comment in all_comments:\n",
    "    comment['author.prev.comments'] = author_comment_num[comment['author']]    \n",
    "    author_comment_num[comment['author']] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Author Removed Count to All Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "author_removed_num = defaultdict(int)\n",
    "\n",
    "for comment in all_comments:\n",
    "    comment['author.prev.removed'] = author_removed_num[comment['author']]  \n",
    "    if(comment['visible']==False):\n",
    "        author_removed_num[comment['author']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "plt.figure(figsize=(10, 3)) \n",
    "plt.hist([math.log1p(x['author.prev.removed']) for x in all_comments])\n",
    "plt.title(\"log1p Number of author's previous comments removed, by comment\", fontsize=\"18\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframes for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset of Comments from The Front Page Observation Period forward\n",
    "Tagged comments with information about the post they were attached to, including:\n",
    "* were they top-level comments or replies?\n",
    "* what flair did the post have\n",
    "* what time was the post made\n",
    "* was the post removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch full post information for all posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_post_ids = [\"t3_\" + post_id for post_id in posts_2016.keys()]\n",
    "additions = 0\n",
    "for post_object in r.get_info(thing_id=all_post_ids):\n",
    "    post = post_object.json_dict\n",
    "    for key in post.keys():\n",
    "        if key not in posts_2016[post['id']].keys():\n",
    "            posts_2016[post['id']][key] = post[key]\n",
    "            additions += 1\n",
    "print(\"{0} fields updated\".format(additions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now attach post-level covariates to comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#list(posts_2016.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_ama(flair, block):\n",
    "    if(flair is None or (isinstance(flair, str))!=True):\n",
    "        return None\n",
    "    if(\"ama\" in flair and block.find(\"nonama\")==-1):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_badpost(flair):\n",
    "    if(flair is None or (isinstance(flair, str))!=True):\n",
    "        return None\n",
    "    return \"badpost\" in flair\n",
    "\n",
    "def strip_ama(flair):\n",
    "    if(flair is None or (isinstance(flair, str))!=True):\n",
    "        return None\n",
    "#    try:\n",
    "    flairs = [x for x in flair.split() if(\"ama\" not in x and \"badpost\" not in x)]\n",
    "#    except:\n",
    "#        import pdb;pdb.set_trace()\n",
    "    if(len(flairs)==0):\n",
    "        return None\n",
    "    return flairs[0] ## Confirmed that this is always only one flair\n",
    "\n",
    "recent_comments_included = []\n",
    "experiment_comments = []\n",
    "for comment in all_comments:\n",
    "    if(comment['author'] == \"CivilServantBot\"):\n",
    "        experiment_comments.append(comment)\n",
    "        continue\n",
    "    post_id = comment['link_id'].replace(\"t3_\", \"\")\n",
    "    if(post_id in posts_2016.keys()):\n",
    "        post = posts_2016[comment['link_id'].replace(\"t3_\", \"\")]\n",
    "        post_created = utc.localize(post['created'])\n",
    "        comment['post.ama'] = is_ama(post['link_flair_css_class'], post['block.id'])\n",
    "        comment['post.badpost'] = is_badpost(post['link_flair_css_class'])\n",
    "        comment['post.flair'] = strip_ama(post['link_flair_css_class'])\n",
    "        comment['post.created'] = post['created']\n",
    "        comment['minutes.since.post.created'] = (comment['created'] - post_created).total_seconds() / 60.\n",
    "#        comment['post.sub.top.minutes'] = post['post.sub.top.minutes']\n",
    "        comment['post.author'] = post['author']\n",
    "        comment['post.visible'] = post['visible']\n",
    "        comment['toplevel'] = comment['link_id'] == comment['parent_id']\n",
    "        comment['post.domain'] = post['domain']\n",
    "        comment['post.day.num']  = (post_created - utc.localize(datetime.datetime(1970,1,1))).days\n",
    "        comment['day.num'] = (comment['created'] - utc.localize(datetime.datetime(1970,1,1))).days\n",
    "        comment['weekday'] = comment['created'].weekday()\n",
    "        comment['weekend'] = (comment['weekday'] >=6)\n",
    "        comment['post.treatment'] = int(post['treatment'])\n",
    "        comment['post.assign.number']  = int(post['treat.number'])\n",
    "        comment['post.block.id'] = post['block.id']\n",
    "        comment['post.block.size']  = post['block.size']\n",
    "\n",
    "        recent_comments_included.append(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Comments Included: {0}\".format(len(recent_comments_included)))\n",
    "print(\"Experiment Comments: {0}\".format(len(experiment_comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c = Counter([x['author'] for x in all_comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c['CivilServantBot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "recent_comment_df = pd.DataFrame(recent_comments_included)\n",
    "recent_comments_filename = \"r_science_comments_science_sticky_09.24.2016.csv\"\n",
    "recent_comment_df.to_csv(os.path.join(\"outputs\",recent_comments_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{0} comments by newcomers\".format(recent_comment_df[recent_comment_df['author.prev.comments']==0].created.count()))\n",
    "#print(\"{0} newcomer comments that were removed\")\n",
    "print(\"{0} comments by newcomers that were removed\".format(recent_comment_df[((recent_comment_df['author.prev.comments']==0) & (recent_comment_df.visible==False))].created.count()))\n",
    "print(\"{0} comments by newcomers that were removed, whose accounts were not later deleted\".format(recent_comment_df[((recent_comment_df['author.prev.comments']==0) & (recent_comment_df.visible==False) & (recent_comment_df.later_deleted==False))].created.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amas = [x for x in list(posts_2016.values()) if is_ama(x['link_flair_css_class'], x['block.id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum([x['num_comments'] for x in amas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Generate and output a post-level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#recent_comments[0]['created']\n",
    "next_period_start = (recent_comments_included[0]['created'] + datetime.timedelta(days=1)).replace(hour = 10, minute=0, second=0)\n",
    "print(next_period_start)\n",
    "datetime.timedelta(days=1).total_seconds()\n",
    "#day_later - datetime.timedelta(hours = day_later.hour, minutes = day_later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from comment_head onward\n",
    "#post_comments = {}\n",
    "for post in posts_2016.values():\n",
    "#    post['newcomer.commenters'] = set()\n",
    "    post['newcomer.comments'] = 0\n",
    "    post['newcomer.comments.experiment.day'] = 0\n",
    "    post['newcomer.comments.experiment.after'] = 0\n",
    "\n",
    "    post['newcomer.comments.removed'] = 0\n",
    "    post['newcomer.comments.removed.experiment.day'] = 0\n",
    "    post['newcomer.comments.removed.experiment.after'] = 0\n",
    "\n",
    "    post['commenters'] = set()\n",
    "    \n",
    "    post['experiment.day'] = post['created'].replace(hour = 5, minute=0, second=0)\n",
    "    post['experiment.day.next'] = (post['experiment.day'] + datetime.timedelta(days=1))\n",
    "    post['experiment.day.minutes'] = int((post['experiment.day.next'] - post['created']).total_seconds() / 60.)\n",
    "                                   \n",
    "    post['num.comments.experiment.day'] = 0\n",
    "    post['num.comments.experiment.after'] = 0\n",
    "                                   \n",
    "    post['num.comments']  = 0\n",
    "    post['num.comments.removed'] = 0\n",
    "    post['num.comments.removed.experiment.day'] = 0\n",
    "    post['num.comments.removed.experiment.after'] = 0\n",
    "                                   \n",
    "    post['post.ama'] = is_ama(post['link_flair_css_class'])\n",
    "    post['post.badpost'] = is_badpost(post['link_flair_css_class'])\n",
    "    post['post.flair'] = strip_ama(post['link_flair_css_class'])\n",
    "    post['weekday'] = post['created'].weekday()\n",
    "    post['weekend'] = (post['weekday'] >=6)\n",
    "    \n",
    "for comment in recent_comments_included:\n",
    "    post = posts_2016[comment['link_id'].replace(\"t3_\", \"\")]\n",
    "    post['commenters'].add(comment['author'])\n",
    "    \n",
    "    \n",
    "    post['num.comments'] += 1\n",
    "    if(comment['created'] <= post['experiment.day.next']):\n",
    "        post['num.comments.experiment.day'] += 1 \n",
    "    else:\n",
    "        post['num.comments.experiment.after'] += 1\n",
    "    \n",
    "    if(comment['visible']!=True):\n",
    "        post['num.comments.removed'] +=1\n",
    "        if(comment['created'] <= post['experiment.day.next']):\n",
    "            post['num.comments.removed.experiment.day'] += 1\n",
    "        else:\n",
    "            post['num.comments.removed.experiment.after'] += 1            \n",
    "        \n",
    "    ## IF THE COMMENT AUTHOR IS A NEWCOMER\n",
    "    if comment['author.prev.comments'] == 0:\n",
    "        post['newcomer.comments'] += 1\n",
    "        \n",
    "        if(comment['created'] <= post['experiment.day.next']):\n",
    "            post['newcomer.comments.experiment.day'] += 1\n",
    "        else:\n",
    "            post['newcomer.comments.experiment.after'] += 1\n",
    "        \n",
    "        if(comment['visible']!=True):\n",
    "            post['newcomer.comments.removed'] += 1\n",
    "    \n",
    "            if(comment['created'] <= post['experiment.day.next']):\n",
    "                post['newcomer.comments.removed.experiment.day'] += 1\n",
    "            else:\n",
    "                post['newcomer.comments.removed.experiment.after'] += 1\n",
    "\n",
    "\n",
    "for post in posts_2016.values():\n",
    "    post['num.commenters'] = len(post['commenters'])\n",
    "    del post['commenters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{0} posts overall\".format(len(list(posts_2016.values()))))\n",
    "print(\"{0} posts within the analysis period\".format(len([x for x in posts_2016.values() if (x['created'] > comment_head and x['created'] <= tail)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent_post_df = pd.DataFrame([x for x in posts_2016.values() if (x['created'] > comment_head and x['created'] <= tail)])\n",
    "recent_posts_filename = \"r_science_posts_\" + earliest_datetime + \"-\" + latest_datetime + \".csv\"\n",
    "recent_post_df.to_csv(os.path.join(\"outputs\", recent_posts_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
